# STUDYnet
**ë¹„ëŒ€ë©´ AI í•™ìŠµì§€ Â· ë™í™”ì±… ì†”ë£¨ì…˜**
- ì¸ê³µì§€ëŠ¥ ì˜ìƒ Â· ë¬¸ì ì¸ì‹ê¸°ìˆ ì„ ì´ìš©í•˜ì—¬, íƒœë¸”ë¦¿ ë˜ëŠ” ìŠ¤ë§ˆíŠ¸í° ì „ Â· í›„ë°© ì¹´ë©”ë¼ë¡œ í•™ìŠµì§€ Â· ë™í™”ì±…ì˜ ìºë¦­í„° ë° TEXTë¥¼ ì‹¤ì‹œê°„ ì¸ì‹í•˜ì—¬ ê° í˜ì´ì§€ì— ë§¤ì¹­ë˜ëŠ” ìŒì›, AR, ë™ì˜ìƒ ë“±ì„ ìë™ ì¬ìƒí•´ì£¼ë©°, ì±… ìœ„ì—ì„œì˜ ì†ê°€ë½ MOTION ì¸ì‹ê³¼ (ì¼ë°˜)íœ í•„ê¸°ì¸ì‹ ê¸°ìˆ ë¡œ, êµì‚¬ ë°©ë¬¸ì„ ëŒ€ì²´í•˜ëŠ” ë¹„ëŒ€ë©´ AI Â· í•™ìŠµì§€ Â· ë™í™”ì±… ì†”ë£¨ì…˜.

<div align="center">
<img width="70%" src="https://github.com/iSPD/STUDYnet/blob/main/images/introduce2.png"/>
</div>

## ìŠ¤ë§ˆíŠ¸í° ì†”ë£¨ì…˜
- ì¸ê³µì§€ëŠ¥ ì˜ìƒ/ë¬¸ì ì¸ì‹ê¸°ìˆ ì„ ì´ìš©, ìŠ¤ë§ˆíŠ¸í° ì¹´ë©”ë¼ë¡œ ë™í™”ì±…ì˜ ìºë¦­í„°, ê¸€ìë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¸ì‹í•˜ì—¬ ê° í˜ì´ì§€ì— ë§¤ì¹­ë˜ëŠ” ì†Œë¦¬ë™í™”, ë™ì˜ìƒ, ARìë£Œ ë“±ì„ ìë™ ì¬ìƒí•´ì£¼ëŠ” ê¸°ìˆ .

<div align="center">
<img width="70%" src="https://github.com/iSPD/STUDYnet/blob/main/images/mommyBook.png"/>
</div>

## í…Œë¸”ë¦¿ ì†”ë£¨ì…˜
- ë¹„ëŒ€ë©´ AI í•™ìŠµì§€ ì†”ë£¨ì…˜. ì±… ìœ„ì—ì„œ ì†ê°€ë½ Motionì¸ì‹ê³¼ (ì¼ë°˜)íœ í•„ê¸°ì¸ì‹ ê¸°ìˆ  ì ìš©.

<div align="center">
<img width="45%" src="https://github.com/iSPD/STUDYnet/blob/main/images/studyBook1.png"/><img width="45%" src="https://github.com/iSPD/STUDYnet/blob/main/images/studyBook2.png"/>

<img width="45%" src="https://github.com/iSPD/STUDYnet/blob/main/images/studyBook3.png"/><img width="45%" src="https://github.com/iSPD/STUDYnet/blob/main/images/studyBook4.png"/>

<img width="45%" src="https://github.com/iSPD/STUDYnet/blob/main/images/studyBook5.png"/><img width="45%" src="https://github.com/iSPD/STUDYnet/blob/main/images/studyBook6.png"/>

<img width="90%" src="https://github.com/iSPD/STUDYnet/blob/main/images/studyBook7.png"/>
</div>

---

## ğŸ•°ï¸ **ê°œë°œ ê¸°ê°„**

- 2020ë…„ 12ì›” 31ì¼ ~ 2022ë…„ 12ì›” 30ì¼

---

## ì œí’ˆ ì„±ëŠ¥

<div align="center">
<img width="45%" src="https://github.com/iSPD/STUDYnet/blob/main/images/%EC%8B%9C%ED%97%98%EC%84%B1%EC%A0%81%EC%84%9C1.PNG"/> <img width="45%" src="https://github.com/iSPD/STUDYnet/blob/main/images/%EC%8B%9C%ED%97%98%EC%84%B1%EC%A0%81%EC%84%9C2.PNG"/>
</div>

---

## Classfication AI Model
ë™í™”ì±… ë° í•™ìŠµì§€ì˜ ê° í˜ì´ì§€ë¥¼ ê°€ê³µí•˜ì—¬, ì—¬ëŸ¬ê°œì˜ ë°ì´í„°ì…‹ìœ¼ë¡œ ë§Œë“  í›„ ìŠ¤ë§ˆíŠ¸í° ë° í…Œë¸”ë¦¿ ì „,í›„ë°© ì¹´ë©”ë¼ì—ì„œ í˜ì´ì§€ ë° í™œë™ ìŠ¤í‹°ì»¤ ì¸ì‹ì„ ìœ„í•´ Classification Modelì—ì„œ Training

<div align="left">
<img width="30%" src="https://github.com/iSPD/STUDYnet/blob/main/images/mommyTale.gif"/>
</div>

### ì‚¬ìš©ëª¨ë¸

[MobileNet_v2_1.4_224](https://github.com/tensorflow/models/tree/master/research/slim)

### ë°ì´í„°ì…‹ ê°€ê³µ
- íœ´ëŒ€í° ë° í…Œë¸”ë¦¿ ì¹´ë©”ë¼ë¡œ ë™í™”ì±… ë° í•™ìŠµì§€ë¥¼ ì¸ì‹ ì‹œ ì¼ì–´ë‚ ìˆ˜ ìˆëŠ” **í™˜ê²½**ë“¤ì„ ê°ì•ˆí•˜ì—¬ ë°ì´í„°ì…‹ ê°€ê³µ. ì•„ë˜ì™€ ê°™ì´ ê°€ê³µ
  - Scale(í¬ê¸°)
  
  - Bright(ë°ê¸°)
  
  - Contrast(ëŒ€ë¹„)
  
  - Rotation(íšŒì „)
  
  - Blur
  
  - ë¹›ë°˜ì‚¬
  
  - ê·¸ë¦¼ì
  
  - ìƒ‰ê°ë³€ê²½

  - *ê¸°íƒ€ê°€ê³µ*

<div align="center">
<img width="100%" src="https://github.com/iSPD/STUDYnet/blob/main/images/datasetExample2.PNG"/>
<b><í˜ì´ì§€ ë‹¹ 420ê°œë¡œ ê°€ê³µ. ìœ„ ì‚¬ì§„ì€ ì˜ˆì‹œ></b>
</div>
  
### ì‚¬ìš© ì–¸ì–´ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬
  
  - Python 3.x.x
  
  - tensorflow

### tfrecord ë³€í™˜ ì˜ˆì œ(Tensorflow ë°ì´í„°ì…‹ í˜•ì‹)
```
python download_and_convert_data_custom.py --dataset_dir=dataBook2/KOR_R/dataset_black
```
  
### Train ì˜ˆì œ
```
  CUDA_VISIBLE_DEVICES=0 python train_image_classifier.py
    --alsologtostderr \
    --checkpoint_path=english/trainEnglish \
    --dataset_dir=datasets/english/recordEnglish \
    --dataset_name=book \
    --dataset_split_name=train \
    --model_name=mobilenet_v2_140
```
  
### TFLite ë³€í™˜ ì˜ˆì œ
- ì¶”ë¡ ê·¸ë˜í”„ ì¶”ì¶œ
```Python
  python3 export_inference_graph.py \
  --alsologtostderr \
  --model_name=mobilenet_v2_140 \
  --image_size=224 \
  --output_file=studyNet/result_korean/mobilenet_v2_224_14.pb
```

- ì¶”ë¡ ê·¸ë˜í”„(Graph)ì™€ CheckPoint íŒŒì¼ í•˜ë‚˜ì— ì €ì¥
```Python
  bazel-bin/tensorflow/python/tools/freeze_graph \
    --input_graph=/home/khkim/tensorflow/tensorflow-recent/tensorflow/book/trains/train_thumb/mobilenet_v2_224_14.pb \
    --input_checkpoint=/home/khkim/tensorflow/tensorflow-recent/tensorflow/bookDemo/trains/train_thumb/model.ckpt-50000 \
    --input_binary=true --output_graph=/home/khkim/tensorflow/tensorflow-recent/tensorflow/bookDemo/trains/train_thumb/book_thumb_big_mobilenet_v2_14.pb \
    --output_node_names=MobilenetV2/Predictions/Reshape_1
    --output_node_names=MobilenetV1/Sigmoid
```  
  
- Androidì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ tfliteë¡œ ë³€í™˜
```Python
  ./bazel-bin/tensorflow/lite/python/tflite_convert \
  --output_file=bookDemo/trains/train_thumb/book_thumb_big_mobilenet_v2_14.tflite \
  --graph_def_file=bookDemo/trains/train_thumb/book_thumb_big_mobilenet_v2_14.pb \
  --input_arrays=input \
  --output_arrays=MobilenetV2/Predictions/Reshape_1 \
  --input_shapes=1,224,224,3 \
  --inference_input_type=FLOAT \
  --inference_type=FLOAT \
  --allow_custom_ops
```  
  
---

## Handwriting Optical Character Recognition (Korean, English)

- deep-text-recognition-benchmark(clovaai) ì°¸ê³ í•˜ì—¬ í•œêµ­ì–´, ì˜ì–´ í•„ê¸° ê¸€ìì²´ ì¸ì‹ ëª¨ë¸ ìƒì„±

- ì•ˆë“œë¡œì´ë“œ ëª¨ë°”ì¼ìš©ìœ¼ë¡œ ëª¨ë¸ ë³€í™˜

- í•œê¸€ í•„ê¸°ì²´ ë°ì´í„°ì…‹ : AI-Hub í•œê¸€ ì†ê¸€ì”¨ ë°ì´í„°ì…‹ 50ë§Œì—¬ê°œ ê°€ê³µ, ì†ê¸€ì”¨ ìˆ˜ì§‘ë°ì´í„°(3ì²œì—¬ê°œ), ê°€ê³µë°ì´í„°(4ë°±ë§Œê°œ)

- ì˜ë¬¸ í•„ê¸°ì²´ ë°ì´í„°ì…‹ : IAM Handwrite ë°ì´í„°ì…‹ 10ë§Œì—¬ê°œ, ì‹¤ì œ ì†ê¸€ì”¨ ìˆ˜ì§‘ë°ì´í„°(7ì²œì—¬ê°œ), ìì²´ ì œì‘ ê°€ê³µë°ì´í„°(4ë°±ë§Œê°œ)

### Dataset

  - í•œêµ­ì–´ í•„ê¸°ì²´ ë°ì´í„° : ê°€ê³µë°ì´í„° ìƒì„± + AI-Hub ë°ì´í„° ì™€ ì‹¤ì œ ì†ê¸€ì”¨ ìˆ˜ì§‘ ë°ì´í„° í˜¼í•© íŠ¸ë ˆì´ë‹.
  
    (1) ê°€ê³µë°ì´í„° - í•œê¸€ í•„ê¸°ì²´ í°íŠ¸ 174ê°œë¡œ êµ¬ì„±í•œ í•œê¸€ ë‹¨ì–´ 5ë§Œì—¬ê°œ, ì´ 4ë°±ë§Œê°œ ë‹¨ì–´ ì´ë¯¸ì§€ ë°ì´í„°ì…‹
  
    (2) AI-Hub í•œê¸€ ì†ê¸€ì”¨ ë°ì´í„°ì…‹ 50ë§Œì—¬ê°œ ê°€ê³µ(ë…¸ì´ì¦ˆ, ë°°ê²½í•©ì„±)
  
    (3) ì‹¤ì œ ì†ê¸€ì”¨ ìˆ˜ì§‘ë°ì´í„°(3ì²œì—¬ê°œ) ì—ì„œ ë‹¨ì–´ bbox ì‘ì—… í›„ ì´ë¯¸ì§€ ìƒì„±.
  
    (4) ê°€ê³µë°ì´í„°, AI-Hub ë°ì´í„° ì™€ ì‹¤ì œ ì†ê¸€ì”¨ ìˆ˜ì§‘ë°ì´í„°ë¥¼ í˜¼í•©í•´ì„œ annotation íŒŒì¼ ì‘ì„±.
  
  - ì˜ì–´ í•„ê¸°ì²´ ë°ì´í„° : ê°€ê³µë°ì´í„° ìƒì„± + IAM ë°ì´í„° ì™€ ì‹¤ì œ ì†ê¸€ì”¨ ìˆ˜ì§‘ ë°ì´í„° í˜¼í•© íŠ¸ë ˆì´ë‹.
  
    (1) ê°€ê³µë°ì´í„° - ì˜ì–´ í•„ê¸°ì²´ í°íŠ¸ 182ê°œë¡œ êµ¬ì„±í•œ ì˜ì–´ ë‹¨ì–´ 2ë§Œì—¬ê°œë¡œ ë°‘ì¤„, ê¸°í˜¸, ë…¸ì´ì¦ˆ í•©ì„±. ì´ 4ë°±ë§Œê°œ ë‹¨ì–´ ì´ë¯¸ì§€ ë°ì´í„°ì…‹	
  
    (2) ì›¹ì—ì„œ ìˆ˜ì§‘í•œ ì˜ë¬¸ í•„ê¸° ë°ì´í„°(ì¼ê¸°,ì—ì„¸ì´ ë“±) ì—ì„œ ë‹¨ì–´ bbox ì‘ì—… í›„ ì´ë¯¸ì§€ ìƒì„±.
  
    (3)	ê°€ê³µë°ì´í„°, IAM ë°ì´í„° ì™€ ì‹¤ì œ ì†ê¸€ì”¨ ìˆ˜ì§‘ë°ì´í„°ë¥¼ í˜¼í•©í•´ì„œ annotation íŒŒì¼ ì‘ì„±.
    
### Train

  - LMDB ë³€í™˜
    ```
    python3 create_lmdb_dataset.py --inputPath ../dataset/handwrite_eng/ --gtFile ../dataset/handwrite_eng/annotation_train.txt --outputPath ../dataset/handwrite_eng/lmdb_train
    ```
  - Train
    ```
    CUDA_VISIBLE_DEVICES=0 python3 train.py --experiment_name handwrite_eng --train_data ../dataset/lmdb_hw_eng/lmdb_train --valid_data ../dataset/lmdb_hw_eng/lmdb_val --select_data / --batch_ratio 1 --Transformation None --FeatureExtraction VGG --SequenceModeling None --Prediction CTC --valInterval 500 --manualSeed 2223 --PAD --num_iter 300000 --output_channel 512 --hidden_size 256
    ```
  - Test
    ```
    CUDA_VISIBLE_DEVICES=0 python3 test.py --eval_data ../dataset/lmdb_hw_eng/lmdb_test --Transformation None --FeatureExtraction VGG --SequenceModeling None --Prediction CTC --saved_model ./saved_models/handwrite_eng/best_accuracy.pth --PAD --output_channel 512 --hidden_size 256
    ```
    
### ëª¨ë¸ ë³€í™˜
  - [TorchScript](https://pytorch.org/docs/stable/jit.html#torchscript)
  
    ```
    CUDA_VISIBLE_DEVICES=-1 python3 demo_for_torchscript.py --Transformation None --FeatureExtraction VGG --SequenceModeling None --Prediction CTC --image_folder ./demo_image --PAD --saved_model ./saved_models/handwrite_eng/best_accuracy.pth
    ```

## Dataset ê°€ê³µ
  - font file, word list, í•©ì„±í•  ë°°ê²½ì´ë¯¸ì§€ ì¤€ë¹„
  - ë‹¤ì–‘í•œ ê¸€ì”¨ì²´, ë†ë„, ë°°ê²½, ë…¸ì´ì¦ˆ, ìŒì˜ ì ìš©
  
  <div align="left">
  <img src="https://github.com/iSPD/STUDYnet/blob/main/images/data/kor/25589_102_ft1.jpg"/>â€ <img src="https://github.com/iSPD/STUDYnet/blob/main/images/data/kor/25594_112_ft1.jpg"/>  <img src="https://github.com/iSPD/STUDYnet/blob/main/images/data/kor/485704_964_ft19.jpg"/>  <img src="https://github.com/iSPD/STUDYnet/blob/main/images/data/kor/485771_1098_ft19.jpg"/>  <img src="https://github.com/iSPD/STUDYnet/blob/main/images/data/kor/51076_1_ft2.jpg"/>  <img src="https://github.com/iSPD/STUDYnet/blob/main/images/data/kor/51106_61_ft2.jpg"/>
  <br>
  <img src="https://github.com/iSPD/STUDYnet/blob/main/images/data/kor/51128_105_ft2.jpg"/>  <img src="https://github.com/iSPD/STUDYnet/blob/main/images/data/kor/51158_165_ft2.jpg"/>  <img src="https://github.com/iSPD/STUDYnet/blob/main/images/data/kor/51491_831_ft2.jpg"/>  <img src="https://github.com/iSPD/STUDYnet/blob/main/images/data/kor/51664_1177_ft2.jpg"/>  <img src="https://github.com/iSPD/STUDYnet/blob/main/images/data/kor/51905_1659_ft2.jpg"/>  <img src="https://github.com/iSPD/STUDYnet/blob/main/images/data/kor/76827_426_ft3.jpg"/>
  
</div>
  <div align="left">
  <img src="https://github.com/iSPD/STUDYnet/blob/main/images/data/eng/103109_59752_ft4.jpg"/> â€<img src="https://github.com/iSPD/STUDYnet/blob/main/images/data/eng/44153_270_ft2.jpg"/>  <img src="https://github.com/iSPD/STUDYnet/blob/main/images/data/eng/661339_226_ft30.jpg"/>  <img src="https://github.com/iSPD/STUDYnet/blob/main/images/data/eng/661349_266_ft30.jpg"/>  <img src="https://github.com/iSPD/STUDYnet/blob/main/images/data/eng/661562_1118_ft30.jpg"/> 
  <br>
  <img src="https://github.com/iSPD/STUDYnet/blob/main/images/data/eng/66185_227_ft3.jpg"/>  <img src="https://github.com/iSPD/STUDYnet/blob/main/images/data/eng/741531_56481_ft33.jpg"/>  <img src="https://github.com/iSPD/STUDYnet/blob/main/images/data/eng/741532_56485_ft33.jpg"/>  <img src="https://github.com/iSPD/STUDYnet/blob/main/images/data/eng/88273_408_ft4.jpg"/>  <img src="https://github.com/iSPD/STUDYnet/blob/main/images/data/eng/88312_564_ft4.jpg"/>
  </div>
  
---

## Motion Recognition

<div align="center">
<img width="45%" src="https://github.com/iSPD/STUDYnet/blob/main/images/hand_landmark.png"/> <img width="45%" src="https://github.com/iSPD/STUDYnet/blob/main/images/%ED%95%99%EC%8A%B5%ED%99%9C%EB%8F%99.gif"/>
</div>

<!--
<div align="center">
<img width="45%" src="https://github.com/iSPD/STUDYnet/blob/main/images/rockPaper.gif"/> <img width="45%" src="https://github.com/iSPD/STUDYnet/blob/main/images/earthView.gif"/>
</div>
-->

- êµ¬ê¸€ì—ì„œ ì œê³µí•˜ëŠ” AI Frameworkì¸ [MediaPipe](https://github.com/google/mediapipe)ì—ì„œ Hand landmarks detection ì‚¬ìš©

- <b>STUDYnet</b>ì—ì„œëŠ” ìœ„ì™€ ê°™ì´ ì†ê°€ë½ ì¸ì‹ ë° Tracking í•˜ì—¬ í•™ìŠµì§€ í„°ì¹˜ í™œë™, ê°€ìœ„ë°”ìœ„ë³´ ê²Œì„ ê°™ì€ Activityì— ì ìš©.

- MediaPipeì—ì„œëŠ” ë‹¤ì–‘í•œ ë¹„ì „ AIê¸°ëŠ¥ì„ íŒŒì´í”„ë¼ì¸ í˜•íƒœë¡œ ì†ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µ. ì¸ì²´ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•˜ëŠ” Detect(ì¸ì‹)ì— ëŒ€í•´ì„œ ì–¼êµ´ì¸ì‹, í¬ì¦ˆ, ê°ì²´ê°ì§€, ëª¨ì…˜íŠ¸ë ˆí‚¹ ë“± ë‹¤ì–‘í•œ í˜•íƒœì˜ ê¸°ëŠ¥ê³¼ ëª¨ë¸ì„ ì œê³µí•¨. pythonë“± ë‹¤ì–‘í•œ ì–¸ì–´ì„ ì§€ì›í•˜ë©°, <b>STUDYnet</b>ì—ì„œëŠ” C++ì½”ë“œë¥¼ ì‚¬ìš©í•˜ë©°, <b>OpenGL ES2.0(Shader)</b>ê³¼ ì—°ê²°í•´ì„œ ì‚¬ìš©

---

## AI Auto Scoring Solution
- OCRê³¼ Image Classificationì„ ì´ìš©í•˜ì—¬ ì •ë‹µ ì±„ì 
  - OCR : **ëª¨ë¸3ê°œ**ë¡œ ì†ê¸€ì”¨ë¥¼ Inferenceí•˜ì—¬ ì¸ì‹ë¥  ê°œì„ . (ëª¨ë¸1, ëª¨ë¸2, ëª¨ë¸3 ëª¨ë‘ ë™ì¼í•˜ê²Œ ì¸ì‹í•˜ë©´ ì¸ì‹ë¥  100%. ëª¨ë¸1, ëª¨ë¸2ê°€ ë™ì¼í•˜ê²Œ ì¸ì‹í•˜ë©´ ì¸ì‹ë¥  66%)
  - Image Classification : í•™ìŠµì§€ì— ìŠ¤í‹°ì»¤ì™€ ê°™ì€ ì´ë¯¸ì§€ë¥¼ ë¶™ì´ëŠ” ê²½ìš° ì¸ì‹í•˜ì—¬ì„œ ìë™ ì±„ì 

<div align="center">
<!--<img width="45%" src="https://github.com/iSPD/STUDYnet/blob/main/images/%EC%9E%90%EB%8F%99%EC%B1%84%EC%A0%90.gif"/>--><img width="45%" src="https://github.com/iSPD/STUDYnet/blob/main/images/%EC%9E%90%EB%8F%99%EC%B1%84%EC%A0%90%EB%85%B9%ED%99%94.gif"/>
</div>
  
---
  
## Advanced PD Image Alignment(ì´ë¯¸ì§€ ì •ë ¬) with Pre-Processing
- ì¹´ë©”ë¼ Previewë¡œ ë“¤ì–´ì˜¤ëŠ” ì±… í˜ì´ì§€ì˜ Edgeë¥¼ ì•Œì•„ë‚´ì„œ ì±…ì˜ ì™¸ê³½ì„  ë° ì¤‘ì•™ì„ ì„ ì•Œì•„ë‚´ì„œ, ì™œê³¡ëœ ë¶€ë¶„ì„ ë³´ì •í›„ KeyPoint ê²€ì¶œ í›„ ì±… ì›ë³¸ KeyPointì™€ Feature Matchingí•˜ì—¬ PD Image Alignmentë¥¼ ì ìš©.
  
### ì‚¬ìš© ì–¸ì–´ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬
  
  - C++
  
  - OpenCV 3.4.x

|Edge Detection with Sobel, Canny|Line Detection with Hough Transform|
|:---:|:---:|
|<img width="100%" src="https://github.com/iSPD/STUDYnet/blob/main/images/1.edgeDetect.jpg"/>|<img width="100%" src="https://github.com/iSPD/STUDYnet/blob/main/images/2.detectEdge.jpg"/>|

|Geometric Perspective(ê¸°í•˜í•™ì  ë³€í™˜)|KeyPoint Detection & <b>Advanced PD Image Alignment</b>|
|:---:|:---:|
|<img width="100%" src="https://github.com/iSPD/STUDYnet/blob/main/images/3.span.jpg"/>|<img width="100%" src="https://github.com/iSPD/STUDYnet/blob/main/images/4.keypointDetect.jpg"/>|
  
|ì±… ì›ë³¸ê³¼ ì¹´ë©”ë¼ë¡œ ë“¤ì–´ì˜¤ëŠ” ì±… Previewê°€ ê²¹ì³ì§„ ìƒíƒœ|
|:---:|
|<img width="50%" src="https://github.com/iSPD/STUDYnet/blob/main/images/5.final.jpg"/>|
  
#### Edge Detection with Sobel, Canny ì˜ˆì œ
  
  ```C++
  //íŠ¹ì„±ì´ ë‹¤ë¥¸ ë‘ Edge Detection ì‚¬ìš©
  Sobel(HRoiMat, HRoiMat, -1, 0, 1);
  Canny(HRoiMat, HRoiMat, cannyThreshold1, cannyThreshold2, 5, true);

  //ì„  ë‘ê»ê²Œ
  Mat dilateSize = getStructuringElement(MORPH_CROSS, Size(1, dilateKSize), Point(-1, -1));
  dilate(HRoiMat, HRoiMat, dilateSize, Point(-1, -1), dilateIteration);
  ```
  
#### Line Detection with Hough Transform ì˜ˆì œ
  
  ```C++
  HoughLinesP(HRoiMat, hLines, 0.5, CV_PI / 180, 50, hMinLength, hMaxLineGap);
  ```
  
#### Geometric Perspective(ê¸°í•˜í•™ì  ë³€í™˜) ì˜ˆì œ
  
  ```C++
  oriPoint[0] = Point2f(gMeetLeftX*resize, gMeetLeftY*resize);//-gUpCut
  oriPoint[1] = Point2f(gMeetRightX*resize, gMeetRightY*resize);//-gUpCut
  oriPoint[2] = Point2f(gPredictLeftX*resize, gPredictLeftY*resize);
  oriPoint[3] = Point2f(gPredictRightX*resize, gPredictRightY*resize);

  int leftHeight = height - belowCropValue;
  int rightHeight = height - belowCropValue;

  tarPoint[0] = Point2f(0, 0);
  tarPoint[1] = Point2f(width, 0);
  tarPoint[2] = Point2f(0, leftHeight);
  tarPoint[3] = Point2f(width, rightHeight);

  trans = getPerspectiveTransform(oriPoint, tarPoint);
  warpPerspective(resultMat, resultMat, trans, resultMat.size());
  ```
  
#### KeyPoint Detection & Image Alignment ì˜ˆì œ
  
  ```C++
  std::vector<KeyPoint> keypoints1;
  Mat descriptors1;
  
  Ptr<SURF> surf = SURF::create(100.0);
  surf->detectAndCompute(compareGrayMat, Mat(), keypoints1, descriptors1);
  
  ...
  
  //PD Alignment
  Mat resultMat = doPDAlignment(leftInputMat, rightInputMat, leftBookFileMat, rightBookFileMat, true/*For Debug*/);
  return resultMat;
  ```
  
---
## LICENSE
- [MIT](https://github.com/iSPD/STUDYnet/blob/main/LICENSE.md)
  
---
  
## ì‚¬ìš© ë°©ë²•
- Contact : ispd_daniel@outlook.kr(ê¹€ê²½í›ˆ), ispd_sally@outlook.kr(ì •ì˜ì„ )  

---
## ë¬¸ì˜ ì‚¬í•­
- (ì£¼)iSPD ì •í•œë³„ ëŒ€í‘œ
- ispd_paul@outlook.kr
- 010-9930-1791
